diff --git a/main.py b/main.py
index 559dead..e82186a 100644
--- a/main.py
+++ b/main.py
@@ -13,7 +13,12 @@ from taggr.permissions_dialog import check_permissions_with_dialog
 from taggr.auth_dialog import check_authentication
 from taggr.project_dialog import prompt_project_selection
 from taggr.splash_screen import show_splash_screen
-from taggr.startup import check_monitor_requirement, check_windows_elevation, check_and_prompt_setup
+from taggr.startup import (
+    check_monitor_requirement, 
+    check_windows_elevation, 
+    check_and_prompt_setup,
+    check_system_requirements
+)
 from taggr.single_instance import check_single_instance
 
 
@@ -110,9 +115,9 @@ def main():
         splash.show_message("Starting up...")
         app.processEvents()
         
-        # Check monitor requirement before permission checks
+        # Check display setup (monitor count) before other checks
         monitor_start = time.time()
-        splash.show_message("Checking system requirements...")
+        splash.show_message("Checking display setup...")
         app.processEvents()
         
         if not check_monitor_requirement(app):
@@ -123,6 +128,28 @@ def main():
             sys.exit(0)
         info(f"⏱ Monitor check took {time.time() - monitor_start:.2f}s")
         
+        # Check hardware requirements (CPU/RAM/disk/power) before permissions
+        hw_check_start = time.time()
+        splash.show_message("Checking hardware requirements...")
+        app.processEvents()
+        
+        # Hide splash before showing dialog to prevent blocking
+        splash.hide()
+        app.processEvents()
+        
+        if not check_system_requirements(app):
+            # System requirements not met - log and exit before permissions check
+            logger.error("Application startup cancelled - system requirements not met")
+            print("Application startup cancelled - system requirements not met.")
+            splash.close()
+            instance_lock.release()  # Release lock before exit
+            sys.exit(0)
+        
+        # Show splash again after requirements check
+        splash.show()
+        app.processEvents()
+        info(f"⏱ Hardware requirements check took {time.time() - hw_check_start:.2f}s")
+        
         # Check permissions before starting the main interface
         permissions_start = time.time()
         splash.show_message("Checking permissions...")
diff --git a/requirements.txt b/requirements.txt
index eed6464..2b36dee 100644
--- a/requirements.txt
+++ b/requirements.txt
@@ -5,6 +5,7 @@ screeninfo
 wmi
 psutil
 pyinstaller
+py-cpuinfo  # For CPU detection in system requirements check
 requests  # For TaggrOps API authentication
 googlemaps  # Official Google Maps Python client for Places API and Geocoding
 pywin32; sys_platform == 'win32'  # For Windows trackpad scroll capture
diff --git a/taggr/ffmpeg_encoder_selector.py b/taggr/ffmpeg_encoder_selector.py
new file mode 100644
index 0000000..2111d95
--- /dev/null
+++ b/taggr/ffmpeg_encoder_selector.py
@@ -0,0 +1,454 @@
+"""
+FFmpeg encoder selection with hardware acceleration detection.
+
+Detects the best available video encoder based on the platform and
+available GPU hardware. Supports NVENC, AMF, QSV, VideoToolbox, and VAAPI.
+
+Environment Variables:
+    TAGGR_FFMPEG_ENCODER: Override encoder selection (e.g., "h264_nvenc", "libx264")
+"""
+
+import os
+import platform
+import re
+import subprocess
+from dataclasses import dataclass
+from typing import List, Optional, Set
+
+from .logger import get_logger
+
+
+@dataclass
+class EncoderChoice:
+    """Result of encoder detection."""
+    name: str  # User-friendly name (e.g., "NVENC H.264")
+    codec: str  # FFmpeg codec name (e.g., "h264_nvenc")
+    extra_args: List[str]  # Additional encoder arguments
+    reason: str  # Why this encoder was chosen
+    is_hardware: bool  # Whether this is hardware-accelerated
+    preset_args: List[str]  # Preset arguments for this encoder
+
+
+# ============================================================================
+# GPU and Encoder Detection
+# ============================================================================
+
+def _get_available_encoders(ffmpeg_path: str = "ffmpeg") -> Set[str]:
+    """
+    Get list of available encoders from ffmpeg.
+    
+    Args:
+        ffmpeg_path: Path to ffmpeg binary
+        
+    Returns:
+        Set of available encoder names
+    """
+    logger = get_logger('taggr.ffmpeg_encoder_selector')
+    
+    try:
+        # Prepare subprocess args
+        kwargs = {'capture_output': True, 'text': True, 'timeout': 10}
+        if platform.system() == "Windows":
+            kwargs['creationflags'] = subprocess.CREATE_NO_WINDOW
+        
+        result = subprocess.run([ffmpeg_path, '-encoders'], **kwargs)
+        
+        encoders = set()
+        for line in result.stdout.split('\n'):
+            # Encoder lines start with space and have format: " V..... codec_name  description"
+            line = line.strip()
+            if line.startswith('V') or line.startswith(' V'):
+                parts = line.split()
+                if len(parts) >= 2:
+                    # Find the codec name (after the flags)
+                    for part in parts[1:]:
+                        if not part.startswith('.') and part.isalnum() or '_' in part:
+                            encoders.add(part)
+                            break
+        
+        logger.debug(f"Available video encoders: {sorted(encoders)[:20]}...")
+        return encoders
+        
+    except subprocess.TimeoutExpired:
+        logger.warning("Timeout while querying ffmpeg encoders")
+        return set()
+    except FileNotFoundError:
+        logger.warning(f"ffmpeg not found at: {ffmpeg_path}")
+        return set()
+    except Exception as e:
+        logger.warning(f"Error querying ffmpeg encoders: {e}")
+        return set()
+
+
+def _detect_gpu_vendor() -> Optional[str]:
+    """
+    Detect the GPU vendor (NVIDIA, AMD, Intel, Apple).
+    
+    Returns:
+        GPU vendor string or None if detection fails
+    """
+    logger = get_logger('taggr.ffmpeg_encoder_selector')
+    system = platform.system()
+    
+    # Windows: Use WMI
+    if system == "Windows":
+        try:
+            import wmi
+            w = wmi.WMI()
+            for gpu in w.Win32_VideoController():
+                name = gpu.Name.upper() if gpu.Name else ""
+                if 'NVIDIA' in name or 'GEFORCE' in name or 'QUADRO' in name or 'RTX' in name or 'GTX' in name:
+                    logger.debug(f"Detected NVIDIA GPU via WMI: {gpu.Name}")
+                    return "NVIDIA"
+                if 'AMD' in name or 'RADEON' in name:
+                    logger.debug(f"Detected AMD GPU via WMI: {gpu.Name}")
+                    return "AMD"
+                if 'INTEL' in name:
+                    logger.debug(f"Detected Intel GPU via WMI: {gpu.Name}")
+                    return "Intel"
+        except Exception as e:
+            logger.debug(f"WMI GPU detection failed: {e}")
+        
+        # Fallback: Check for NVIDIA driver directories
+        nvidia_dirs = [
+            r"C:\Program Files\NVIDIA Corporation",
+            r"C:\Windows\System32\nvapi64.dll",
+        ]
+        for path in nvidia_dirs:
+            if os.path.exists(path):
+                logger.debug(f"Detected NVIDIA via driver path: {path}")
+                return "NVIDIA"
+    
+    # macOS: Use system_profiler
+    elif system == "Darwin":
+        try:
+            result = subprocess.run(
+                ['system_profiler', 'SPDisplaysDataType'],
+                capture_output=True, text=True, timeout=10
+            )
+            output = result.stdout.upper()
+            
+            # Apple Silicon has integrated GPU
+            if 'APPLE' in output or 'M1' in output or 'M2' in output or 'M3' in output or 'M4' in output:
+                logger.debug("Detected Apple Silicon GPU")
+                return "Apple"
+            if 'AMD' in output or 'RADEON' in output:
+                logger.debug("Detected AMD GPU on macOS")
+                return "AMD"
+            if 'INTEL' in output:
+                logger.debug("Detected Intel GPU on macOS")
+                return "Intel"
+            if 'NVIDIA' in output:
+                logger.debug("Detected NVIDIA GPU on macOS")
+                return "NVIDIA"
+                
+        except Exception as e:
+            logger.debug(f"macOS GPU detection failed: {e}")
+        
+        # Apple Silicon detection via CPU
+        try:
+            result = subprocess.run(
+                ['sysctl', '-n', 'machdep.cpu.brand_string'],
+                capture_output=True, text=True, timeout=5
+            )
+            if 'apple' in result.stdout.lower():
+                logger.debug("Detected Apple Silicon via CPU brand")
+                return "Apple"
+        except Exception:
+            pass
+    
+    # Linux: Use lspci
+    elif system == "Linux":
+        try:
+            result = subprocess.run(
+                ['lspci'],
+                capture_output=True, text=True, timeout=10
+            )
+            output = result.stdout.upper()
+            
+            if 'NVIDIA' in output:
+                logger.debug("Detected NVIDIA GPU via lspci")
+                return "NVIDIA"
+            if 'AMD' in output or 'ATI' in output:
+                logger.debug("Detected AMD GPU via lspci")
+                return "AMD"
+            if 'INTEL' in output and ('VGA' in output or 'DISPLAY' in output or 'GRAPHICS' in output):
+                logger.debug("Detected Intel GPU via lspci")
+                return "Intel"
+                
+        except Exception as e:
+            logger.debug(f"lspci GPU detection failed: {e}")
+    
+    logger.debug("Could not detect GPU vendor")
+    return None
+
+
+def _find_vaapi_device() -> Optional[str]:
+    """
+    Find VAAPI render device on Linux.
+    
+    Returns:
+        Path to render device (e.g., /dev/dri/renderD128) or None
+    """
+    logger = get_logger('taggr.ffmpeg_encoder_selector')
+    
+    if platform.system() != "Linux":
+        return None
+    
+    import glob
+    devices = sorted(glob.glob('/dev/dri/renderD*'))
+    
+    if devices:
+        device = devices[0]
+        logger.debug(f"Found VAAPI device: {device}")
+        return device
+    
+    logger.debug("No VAAPI device found")
+    return None
+
+
+def _get_encoder_preset_args(codec: str) -> List[str]:
+    """
+    Get appropriate preset arguments for an encoder.
+    
+    Args:
+        codec: FFmpeg codec name
+        
+    Returns:
+        List of preset arguments
+    """
+    codec_lower = codec.lower()
+    
+    # NVENC: Use p1 preset (fastest)
+    if 'nvenc' in codec_lower:
+        return ['-preset', 'p1']
+    
+    # QSV: Use veryfast preset
+    if 'qsv' in codec_lower:
+        return ['-preset', 'veryfast']
+    
+    # AMF: No preset (uses default)
+    if 'amf' in codec_lower:
+        return []
+    
+    # VAAPI: No preset
+    if 'vaapi' in codec_lower:
+        return []
+    
+    # VideoToolbox: No preset
+    if 'videotoolbox' in codec_lower:
+        return []
+    
+    # Software (libx264/libx265): Use ultrafast
+    if codec_lower in ('libx264', 'libx265'):
+        return ['-preset', 'ultrafast']
+    
+    return []
+
+
+# ============================================================================
+# Encoder Selection
+# ============================================================================
+
+def detect_best_encoder(ffmpeg_path: str = "ffmpeg", prefer_hevc: bool = False) -> EncoderChoice:
+    """
+    Detect the best available video encoder for the current system.
+    
+    Selection priority:
+    1. Environment override (TAGGR_FFMPEG_ENCODER)
+    2. Hardware encoders based on GPU vendor:
+       - NVIDIA: NVENC (h264_nvenc / hevc_nvenc)
+       - AMD: AMF (h264_amf / hevc_amf)
+       - Intel: QSV (h264_qsv / hevc_qsv)
+       - Apple: VideoToolbox (h264_videotoolbox / hevc_videotoolbox)
+       - Linux VAAPI: h264_vaapi / hevc_vaapi
+    3. Software fallback: libx264 / libx265
+    
+    Args:
+        ffmpeg_path: Path to ffmpeg binary
+        prefer_hevc: If True, prefer HEVC/H.265 over H.264 when available
+        
+    Returns:
+        EncoderChoice with selected encoder details
+    """
+    logger = get_logger('taggr.ffmpeg_encoder_selector')
+    logger.info("Detecting best video encoder...")
+    
+    available_encoders = _get_available_encoders(ffmpeg_path)
+    system = platform.system()
+    
+    # Check for environment override
+    env_encoder = os.environ.get('TAGGR_FFMPEG_ENCODER', '').strip()
+    if env_encoder:
+        if env_encoder in available_encoders:
+            logger.info(f"Using encoder from TAGGR_FFMPEG_ENCODER: {env_encoder}")
+            preset_args = _get_encoder_preset_args(env_encoder)
+            env_encoder_lower = env_encoder.lower()
+            is_hw = 'nvenc' in env_encoder_lower or 'qsv' in env_encoder_lower or \
+                    'amf' in env_encoder_lower or 'vaapi' in env_encoder_lower or \
+                    'videotoolbox' in env_encoder_lower
+            return EncoderChoice(
+                name=f"Override: {env_encoder}",
+                codec=env_encoder,
+                extra_args=[],
+                reason=f"Encoder set via TAGGR_FFMPEG_ENCODER environment variable",
+                is_hardware=is_hw,
+                preset_args=preset_args
+            )
+        else:
+            logger.warning(f"TAGGR_FFMPEG_ENCODER={env_encoder} not available in ffmpeg, ignoring")
+    
+    gpu_vendor = _detect_gpu_vendor()
+    logger.info(f"Detected GPU vendor: {gpu_vendor or 'Unknown'}")
+    
+    # Platform-specific encoder selection
+    
+    # Windows candidates
+    if system == "Windows":
+        candidates = []
+        
+        if prefer_hevc:
+            if gpu_vendor == "NVIDIA":
+                candidates.extend(['hevc_nvenc', 'h264_nvenc'])
+            elif gpu_vendor == "AMD":
+                candidates.extend(['hevc_amf', 'h264_amf'])
+            elif gpu_vendor == "Intel":
+                candidates.extend(['hevc_qsv', 'h264_qsv'])
+            else:
+                candidates.extend(['hevc_nvenc', 'hevc_amf', 'hevc_qsv', 'h264_nvenc', 'h264_amf', 'h264_qsv'])
+        else:
+            if gpu_vendor == "NVIDIA":
+                candidates.extend(['h264_nvenc', 'hevc_nvenc'])
+            elif gpu_vendor == "AMD":
+                candidates.extend(['h264_amf', 'hevc_amf'])
+            elif gpu_vendor == "Intel":
+                candidates.extend(['h264_qsv', 'hevc_qsv'])
+            else:
+                candidates.extend(['h264_nvenc', 'h264_amf', 'h264_qsv', 'hevc_nvenc', 'hevc_amf', 'hevc_qsv'])
+        
+        for codec in candidates:
+            if codec in available_encoders:
+                preset_args = _get_encoder_preset_args(codec)
+                codec_lower = codec.lower()
+                codec_type = 'HEVC' if 'hevc' in codec_lower else 'H.264'
+                
+                if 'nvenc' in codec_lower:
+                    hw_name = "NVENC"
+                elif 'amf' in codec_lower:
+                    hw_name = "AMF"
+                elif 'qsv' in codec_lower:
+                    hw_name = "QSV"
+                else:
+                    hw_name = "Hardware"
+                
+                logger.info(f"Selected hardware encoder: {codec} ({hw_name} {codec_type})")
+                return EncoderChoice(
+                    name=f"{hw_name} {codec_type}",
+                    codec=codec,
+                    extra_args=[],
+                    reason=f"{gpu_vendor or 'System'} GPU detected, using {hw_name} acceleration",
+                    is_hardware=True,
+                    preset_args=preset_args
+                )
+    
+    # macOS candidates
+    elif system == "Darwin":
+        candidates = []
+        
+        if prefer_hevc:
+            candidates = ['hevc_videotoolbox', 'h264_videotoolbox']
+        else:
+            candidates = ['h264_videotoolbox', 'hevc_videotoolbox']
+        
+        for codec in candidates:
+            if codec in available_encoders:
+                preset_args = _get_encoder_preset_args(codec)
+                codec_lower = codec.lower()
+                codec_type = 'HEVC' if 'hevc' in codec_lower else 'H.264'
+                
+                logger.info(f"Selected hardware encoder: {codec} (VideoToolbox {codec_type})")
+                return EncoderChoice(
+                    name=f"VideoToolbox {codec_type}",
+                    codec=codec,
+                    extra_args=[],
+                    reason="macOS VideoToolbox hardware acceleration",
+                    is_hardware=True,
+                    preset_args=preset_args
+                )
+    
+    # Linux candidates
+    elif system == "Linux":
+        candidates = []
+        vaapi_device = _find_vaapi_device()
+        
+        if prefer_hevc:
+            if gpu_vendor == "NVIDIA":
+                candidates.extend(['hevc_nvenc', 'h264_nvenc'])
+            # VAAPI for Intel/AMD
+            if vaapi_device:
+                candidates.extend(['hevc_vaapi', 'h264_vaapi'])
+            if gpu_vendor == "Intel":
+                candidates.extend(['hevc_qsv', 'h264_qsv'])
+        else:
+            if gpu_vendor == "NVIDIA":
+                candidates.extend(['h264_nvenc', 'hevc_nvenc'])
+            if vaapi_device:
+                candidates.extend(['h264_vaapi', 'hevc_vaapi'])
+            if gpu_vendor == "Intel":
+                candidates.extend(['h264_qsv', 'hevc_qsv'])
+        
+        for codec in candidates:
+            if codec in available_encoders:
+                preset_args = _get_encoder_preset_args(codec)
+                codec_lower = codec.lower()
+                codec_type = 'HEVC' if 'hevc' in codec_lower else 'H.264'
+                extra_args = []
+                
+                if 'nvenc' in codec_lower:
+                    hw_name = "NVENC"
+                elif 'vaapi' in codec_lower:
+                    hw_name = "VAAPI"
+                    if vaapi_device:
+                        extra_args = ['-hwaccel', 'vaapi', '-vaapi_device', vaapi_device]
+                elif 'qsv' in codec_lower:
+                    hw_name = "QSV"
+                else:
+                    hw_name = "Hardware"
+                
+                logger.info(f"Selected hardware encoder: {codec} ({hw_name} {codec_type})")
+                return EncoderChoice(
+                    name=f"{hw_name} {codec_type}",
+                    codec=codec,
+                    extra_args=extra_args,
+                    reason=f"{gpu_vendor or 'System'} GPU detected, using {hw_name} acceleration",
+                    is_hardware=True,
+                    preset_args=preset_args
+                )
+    
+    # Software fallback
+    software_codec = 'libx265' if prefer_hevc and 'libx265' in available_encoders else 'libx264'
+    
+    if software_codec in available_encoders:
+        codec_type = 'HEVC' if software_codec.lower() == 'libx265' else 'H.264'
+        preset_args = _get_encoder_preset_args(software_codec)
+        
+        logger.warning(f"No hardware encoder available, using software: {software_codec}")
+        return EncoderChoice(
+            name=f"Software {codec_type}",
+            codec=software_codec,
+            extra_args=[],
+            reason="No compatible hardware encoder found, using software encoding",
+            is_hardware=False,
+            preset_args=preset_args
+        )
+    
+    # Ultimate fallback (should rarely happen)
+    logger.error("No suitable encoder found, defaulting to libx264")
+    return EncoderChoice(
+        name="Software H.264 (fallback)",
+        codec="libx264",
+        extra_args=[],
+        reason="Fallback encoder - no other encoders detected",
+        is_hardware=False,
+        preset_args=['-preset', 'ultrafast']
+    )
diff --git a/taggr/metadata.py b/taggr/metadata.py
index 1c525b1..98e0537 100644
--- a/taggr/metadata.py
+++ b/taggr/metadata.py
@@ -1,12 +1,73 @@
 import json
 import os
+import platform
 import uuid
 from datetime import datetime, timezone
 from platform import uname
+from typing import Tuple
 
 from screeninfo import get_monitors
 
 from . import __version__
+from .logger import get_logger
+
+
+def _get_desktop_dimensions() -> Tuple[int, int]:
+    """
+    Get the total desktop dimensions (virtual screen size).
+    
+    This accounts for multi-monitor setups by returning the bounding box
+    of all monitors, or falls back to the primary monitor.
+    
+    Returns:
+        Tuple of (width, height) in pixels
+    """
+    logger = get_logger('taggr.metadata')
+    system = platform.system()
+    
+    # Windows: Use GetSystemMetrics for virtual screen dimensions
+    if system == "Windows":
+        try:
+            import ctypes
+            user32 = ctypes.windll.user32
+            # SM_CXVIRTUALSCREEN (78) and SM_CYVIRTUALSCREEN (79)
+            # These give the total size of the virtual desktop
+            width = user32.GetSystemMetrics(78)
+            height = user32.GetSystemMetrics(79)
+            if width > 0 and height > 0:
+                logger.debug(f"Desktop dimensions via GetSystemMetrics: {width}x{height}")
+                return (width, height)
+        except Exception as e:
+            logger.debug(f"Windows GetSystemMetrics failed: {e}")
+    
+    # Fallback: Use bounding box of all monitors
+    try:
+        monitors = get_monitors()
+        if monitors:
+            # Calculate bounding box
+            min_x = min(m.x for m in monitors)
+            min_y = min(m.y for m in monitors)
+            max_x = max(m.x + m.width for m in monitors)
+            max_y = max(m.y + m.height for m in monitors)
+            
+            width = max_x - min_x
+            height = max_y - min_y
+            
+            if width > 0 and height > 0:
+                logger.debug(f"Desktop dimensions via monitor bounding box: {width}x{height}")
+                return (width, height)
+            
+            # Single monitor fallback
+            main = monitors[0]
+            if main.width > 0 and main.height > 0:
+                logger.debug(f"Desktop dimensions via primary monitor: {main.width}x{main.height}")
+                return (main.width, main.height)
+    except Exception as e:
+        logger.debug(f"Monitor detection failed: {e}")
+    
+    # Last resort
+    logger.warning("Could not detect desktop dimensions, using fallback (1, 1)")
+    return (1, 1)
 
 
 class MetadataManager:
@@ -15,6 +76,7 @@ class MetadataManager:
     """
     
     def __init__(self, recording_path: str, natural_scrolling: bool, video_resolution: str = "1920x1080", fps: int = 30, task_uuid: str = None, task_slug: str = None):
+        self.logger = get_logger('taggr.metadata')
         self.recording_path = recording_path
         
         self.metadata = uname()._asdict()
@@ -30,10 +92,10 @@ class MetadataManager:
         if task_slug:
             self.metadata["task_slug"] = task_slug
 
-        # Get original screen resolution
-        main_monitor = get_monitors()[0]
-        self.metadata["screen_width"] = main_monitor.width
-        self.metadata["screen_height"] = main_monitor.height
+        # Get desktop dimensions (virtual screen for multi-monitor support)
+        screen_width, screen_height = _get_desktop_dimensions()
+        self.metadata["screen_width"] = screen_width
+        self.metadata["screen_height"] = screen_height
         
         # Parse and store video output resolution
         try:
@@ -42,17 +104,20 @@ class MetadataManager:
             self.metadata["video_height"] = int(video_height)
         except Exception:
             # Default to screen resolution if parsing fails
-            self.metadata["video_width"] = main_monitor.width
-            self.metadata["video_height"] = main_monitor.height
+            self.metadata["video_width"] = screen_width
+            self.metadata["video_height"] = screen_height
         
         # Store video FPS
         self.metadata["video_fps"] = fps
         
-        # Calculate coordinate correction factors (scale from screen to video coordinates)
-        # These factors map screen coordinates to video coordinates
-        # Note: coordinates in events.jsonl are already scaled, so we don't store these in metadata
-        self.scale_x = self.metadata["video_width"] / self.metadata["screen_width"]
-        self.scale_y = self.metadata["video_height"] / self.metadata["screen_height"]
+        # Compute letterbox-aware coordinate mapping
+        self._compute_letterbox_mapping(
+            screen_width, screen_height,
+            self.metadata["video_width"], self.metadata["video_height"]
+        )
+        
+        self.logger.debug(f"Screen: {screen_width}x{screen_height}, Video: {self.metadata['video_width']}x{self.metadata['video_height']}")
+        self.logger.debug(f"Letterbox mapping: scale={self.video_scale_factor:.4f}, pad=({self.video_pad_x}, {self.video_pad_y}), scaled_size={self.video_scaled_width}x{self.video_scaled_height}")
         
         # Initialize timing data for synchronization
         # Recording flow: ffmpeg starts -> first frame captured -> input capture starts
@@ -84,6 +149,66 @@ class MetadataManager:
         
         self.metadata["scroll_direction"] = -1 if natural_scrolling else 1
 
+    def _compute_letterbox_mapping(self, screen_w: int, screen_h: int, video_w: int, video_h: int):
+        """
+        Compute letterbox-aware mapping from screen coordinates to video coordinates.
+        
+        When the video has a different aspect ratio than the screen, letterboxing
+        is applied (black bars on sides/top). This method calculates the scale
+        factor and padding offsets to correctly map screen coordinates to the
+        visible area within the letterboxed video.
+        
+        Args:
+            screen_w: Screen/desktop width in pixels
+            screen_h: Screen/desktop height in pixels
+            video_w: Output video width in pixels
+            video_h: Output video height in pixels
+        """
+        # Avoid division by zero
+        if screen_w <= 0 or screen_h <= 0 or video_w <= 0 or video_h <= 0:
+            self.logger.warning("Invalid dimensions for letterbox mapping, using 1:1 fallback")
+            self.video_scale_factor = 1.0
+            self.video_pad_x = 0
+            self.video_pad_y = 0
+            self.video_scaled_width = video_w if video_w > 0 else 1
+            self.video_scaled_height = video_h if video_h > 0 else 1
+            # Compatibility: set scale_x/scale_y to scale_factor
+            self.scale_x = self.video_scale_factor
+            self.scale_y = self.video_scale_factor
+            return
+        
+        # Calculate scale factor to fit screen into video while preserving aspect ratio
+        # This matches ffmpeg's scale=...:force_original_aspect_ratio=decrease
+        scale = min(video_w / screen_w, video_h / screen_h)
+        
+        # Calculate scaled dimensions (how big the screen content appears in video)
+        scaled_w = int(round(screen_w * scale))
+        scaled_h = int(round(screen_h * scale))
+        
+        # Calculate padding (letterbox bars) - centered using integer math
+        # This matches ffmpeg's pad=...(ow-iw)/2:(oh-ih)/2
+        pad_x = (video_w - scaled_w) // 2
+        pad_y = (video_h - scaled_h) // 2
+        
+        # Store mapping parameters
+        self.video_scale_factor = scale
+        self.video_pad_x = pad_x
+        self.video_pad_y = pad_y
+        self.video_scaled_width = scaled_w
+        self.video_scaled_height = scaled_h
+        
+        # Compatibility: set scale_x/scale_y to scale_factor for consistent scaling
+        # (letterboxing uses uniform scale, no separate x/y scaling)
+        self.scale_x = scale
+        self.scale_y = scale
+        
+        # Store in metadata for reference
+        self.metadata["letterbox_scale"] = scale
+        self.metadata["letterbox_pad_x"] = pad_x
+        self.metadata["letterbox_pad_y"] = pad_y
+        self.metadata["letterbox_scaled_width"] = scaled_w
+        self.metadata["letterbox_scaled_height"] = scaled_h
+
     def save_metadata(self):
         # Calculate and store the latency offset before saving
         # This is the time between first frame capture and input capture start
@@ -107,16 +232,23 @@ class MetadataManager:
     
     def scale_coordinates(self, x: float, y: float) -> tuple[float, float]:
         """
-        Scale screen coordinates to video coordinates using correction factors.
+        Scale screen coordinates to video coordinates using letterbox-aware mapping.
+        
+        Applies uniform scaling and adds padding offset to map screen coordinates
+        to the correct position within the letterboxed video frame.
+        
+        Formula: scaled_coord = screen_coord * scale_factor + padding
         
         Args:
             x: X coordinate in screen space
             y: Y coordinate in screen space
             
         Returns:
-            Tuple of (scaled_x, scaled_y) in video space
+            Tuple of (scaled_x, scaled_y) in video space (within letterboxed frame)
         """
-        return (x * self.scale_x, y * self.scale_y)
+        scaled_x = x * self.video_scale_factor + self.video_pad_x
+        scaled_y = y * self.video_scale_factor + self.video_pad_y
+        return (scaled_x, scaled_y)
     
     def set_recording_start_time(self, timestamp_ms: float):
         """
diff --git a/taggr/recorder.py b/taggr/recorder.py
index 4ffa7f7..1d6399e 100644
--- a/taggr/recorder.py
+++ b/taggr/recorder.py
@@ -68,23 +68,43 @@ class Recorder(QThread):
         except Exception as e:
             self.logger.debug(f"Failed to emit processing state: {e}")
         
+    def _get_current_frame_timing(self):
+        """
+        Get the current frame timing (index and PTS) from the screen recorder.
+        
+        Returns:
+            Tuple of (frame_index, frame_pts_seconds, perf_counter_ms) or (-1, -1.0, -1.0) if unavailable
+        """
+        if not self.screen_recorder:
+            return (-1, -1.0, -1.0)
+        try:
+            return self.screen_recorder.get_current_frame_timing()
+        except AttributeError:
+            # Fallback if get_current_frame_timing not available
+            try:
+                frame_index = self.screen_recorder.get_current_frame_index()
+                return (frame_index if frame_index is not None else -1, -1.0, -1.0)
+            except AttributeError:
+                return (-1, -1.0, -1.0)
+
     def on_move(self, x, y):
         now = time.perf_counter()
         if now - self._last_move_ts < self._move_throttle_interval:
             return
         self._last_move_ts = now
-        frame_index = self._get_current_frame_index()
-        self.event_queue.put(("move", now * 1000, frame_index, x, y), block=False)
+        frame_index, frame_pts, _ = self._get_current_frame_timing()
+        # Event tuple includes raw coords and frame timing for PTS-based sync
+        self.event_queue.put(("move", now * 1000, frame_index, frame_pts, x, y), block=False)
         
     def on_click(self, x, y, button, pressed):
         now = time.perf_counter()
-        frame_index = self._get_current_frame_index()
-        self.event_queue.put(("click", now * 1000, frame_index, x, y, button, pressed), block=False)
+        frame_index, frame_pts, _ = self._get_current_frame_timing()
+        self.event_queue.put(("click", now * 1000, frame_index, frame_pts, x, y, button, pressed), block=False)
     
     def on_scroll(self, x, y, dx, dy):
         now = time.perf_counter()
-        frame_index = self._get_current_frame_index()
-        self.event_queue.put(("scroll", now * 1000, frame_index, x, y, dx, dy), block=False)
+        frame_index, frame_pts, _ = self._get_current_frame_timing()
+        self.event_queue.put(("scroll", now * 1000, frame_index, frame_pts, x, y, dx, dy), block=False)
     
     def _windows_scroll_callback(self, x, y, dx, dy):
         """
@@ -92,8 +112,8 @@ class Recorder(QThread):
         This captures trackpad scroll events that pynput might miss.
         """
         now = time.perf_counter()
-        frame_index = self._get_current_frame_index()
-        self.event_queue.put(("scroll", now * 1000, frame_index, x, y, dx, dy), block=False)
+        frame_index, frame_pts, _ = self._get_current_frame_timing()
+        self.event_queue.put(("scroll", now * 1000, frame_index, frame_pts, x, y, dx, dy), block=False)
     
     def _normalize_key_name(self, key):
         """
@@ -230,66 +250,117 @@ class Recorder(QThread):
         except AttributeError:
             return -1
 
-    def _process_event(self, raw_event):
-        """Convert raw tuple events into JSON-friendly dicts."""
+    def _process_event(self, raw_event, video_start_ms: float):
+        """
+        Convert raw tuple events into JSON-friendly dicts.
+        
+        Event tuples now include frame_pts for PTS-based synchronization:
+        - ("move", ts_ms, frame_index, frame_pts, x, y)
+        - ("click", ts_ms, frame_index, frame_pts, x, y, button, pressed)
+        - ("scroll", ts_ms, frame_index, frame_pts, x, y, dx, dy)
+        - ("press", ts_ms, frame_index, frame_pts, key)
+        - ("release", ts_ms, frame_index, frame_pts, key)
+        
+        Args:
+            raw_event: Event tuple
+            video_start_ms: Video start timestamp for fallback timing calculation
+            
+        Returns:
+            Processed event dict or None
+        """
         evt_type = raw_event[0]
         ts_ms = raw_event[1]
         frame_index = raw_event[2] if len(raw_event) > 2 else -1
+        frame_pts = raw_event[3] if len(raw_event) > 3 else -1.0
+        
+        # Calculate second_in_video using PTS when available (>=0), else fallback to timestamp-based
+        if frame_pts >= 0:
+            second_in_video = frame_pts
+        else:
+            second_in_video = (ts_ms - video_start_ms) / 1000.0
         
         if evt_type == "move":
-            x, y = raw_event[3], raw_event[4]
+            x, y = raw_event[4], raw_event[5]
             scaled_x, scaled_y = self.metadata_manager.scale_coordinates(x, y)
             return {
                 "time_stamp_ms": ts_ms,
                 "frame_index": frame_index,
+                "frame_pts_seconds": frame_pts if frame_pts >= 0 else None,
+                "second_in_video": second_in_video,
                 "action": "move",
                 "x": scaled_x,
-                "y": scaled_y
+                "y": scaled_y,
+                "raw_x": x,
+                "raw_y": y
             }
         
         if evt_type == "click":
-            x, y, button, pressed = raw_event[3], raw_event[4], raw_event[5], raw_event[6]
+            x, y, button, pressed = raw_event[4], raw_event[5], raw_event[6], raw_event[7]
             scaled_x, scaled_y = self.metadata_manager.scale_coordinates(x, y)
             name = button.name if hasattr(button, 'name') else str(button)
             return {
                 "time_stamp_ms": ts_ms,
                 "frame_index": frame_index,
+                "frame_pts_seconds": frame_pts if frame_pts >= 0 else None,
+                "second_in_video": second_in_video,
                 "action": "click",
                 "x": scaled_x,
                 "y": scaled_y,
+                "raw_x": x,
+                "raw_y": y,
                 "button": name,
                 "pressed": pressed
             }
         
         if evt_type == "scroll":
-            x, y, dx, dy = raw_event[3], raw_event[4], raw_event[5], raw_event[6]
+            x, y, dx, dy = raw_event[4], raw_event[5], raw_event[6], raw_event[7]
             scaled_x, scaled_y = self.metadata_manager.scale_coordinates(x, y)
             return {
                 "time_stamp_ms": ts_ms,
                 "frame_index": frame_index,
+                "frame_pts_seconds": frame_pts if frame_pts >= 0 else None,
+                "second_in_video": second_in_video,
                 "action": "scroll",
                 "x": scaled_x,
                 "y": scaled_y,
+                "raw_x": x,
+                "raw_y": y,
                 "dx": dx,
                 "dy": dy
             }
         
         if evt_type == "press":
-            key = raw_event[3]
+            x, y = raw_event[4], raw_event[5]
+            key = raw_event[6]
+            scaled_x, scaled_y = self.metadata_manager.scale_coordinates(x, y)
             return {
                 "time_stamp_ms": ts_ms,
                 "frame_index": frame_index,
+                "frame_pts_seconds": frame_pts if frame_pts >= 0 else None,
+                "second_in_video": second_in_video,
                 "action": "press",
-                "name": self._normalize_key_name(key)
+                "name": self._normalize_key_name(key),
+                "x": scaled_x,
+                "y": scaled_y,
+                "raw_x": x,
+                "raw_y": y
             }
         
         if evt_type == "release":
-            key = raw_event[3]
+            x, y = raw_event[4], raw_event[5]
+            key = raw_event[6]
+            scaled_x, scaled_y = self.metadata_manager.scale_coordinates(x, y)
             return {
                 "time_stamp_ms": ts_ms,
                 "frame_index": frame_index,
+                "frame_pts_seconds": frame_pts if frame_pts >= 0 else None,
+                "second_in_video": second_in_video,
                 "action": "release",
-                "name": self._normalize_key_name(key)
+                "name": self._normalize_key_name(key),
+                "x": scaled_x,
+                "y": scaled_y,
+                "raw_x": x,
+                "raw_y": y
             }
         
         return None
@@ -305,15 +376,77 @@ class Recorder(QThread):
         except Exception as e:
             self.logger.warning(f"Could not adjust process priority: {e}")
 
+    def _get_cursor_position(self):
+        """
+        Get current cursor position relative to the virtual desktop.
+        
+        Uses platform-specific methods to ensure coordinates are in the same
+        coordinate space as the desktop dimensions used for letterbox mapping.
+        
+        On Windows: Uses GetCursorPos which returns virtual screen coordinates
+        On macOS: Uses NSEvent.mouseLocation with screen coordinate conversion
+        On Linux: Falls back to pynput which uses X11/Wayland coordinates
+        
+        Returns:
+            Tuple of (x, y) coordinates relative to the virtual desktop origin
+        """
+        current_system = system()
+        
+        # Windows: Use GetCursorPos for virtual screen coordinates
+        if current_system == "Windows":
+            try:
+                import ctypes
+                
+                class POINT(ctypes.Structure):
+                    _fields_ = [("x", ctypes.c_long), ("y", ctypes.c_long)]
+                
+                pt = POINT()
+                ctypes.windll.user32.GetCursorPos(ctypes.byref(pt))
+                return (pt.x, pt.y)
+            except Exception:
+                pass
+        
+        # macOS: Use NSEvent for screen-relative coordinates
+        elif current_system == "Darwin":
+            try:
+                from AppKit import NSEvent, NSScreen
+                
+                # Get mouse location in screen coordinates (origin at bottom-left)
+                location = NSEvent.mouseLocation()
+                
+                # Get the main screen's frame to calculate the total desktop height
+                # for coordinate conversion (macOS uses bottom-left origin)
+                screens = NSScreen.screens()
+                if screens:
+                    # Find the total bounds of all screens
+                    min_x = min(screen.frame().origin.x for screen in screens)
+                    max_y = max(screen.frame().origin.y + screen.frame().size.height for screen in screens)
+                    
+                    # Convert from bottom-left origin to top-left origin
+                    x = location.x - min_x
+                    y = max_y - location.y
+                    return (int(x), int(y))
+            except Exception:
+                pass
+        
+        # Linux / Fallback: Use pynput mouse controller
+        try:
+            controller = mouse.Controller()
+            return controller.position
+        except Exception:
+            return (0, 0)
+
     def on_press(self, key):
         now = time.perf_counter()
-        frame_index = self._get_current_frame_index()
-        self.event_queue.put(("press", now * 1000, frame_index, key), block=False)
+        frame_index, frame_pts, _ = self._get_current_frame_timing()
+        x, y = self._get_cursor_position()
+        self.event_queue.put(("press", now * 1000, frame_index, frame_pts, x, y, key), block=False)
 
     def on_release(self, key):
         now = time.perf_counter()
-        frame_index = self._get_current_frame_index()
-        self.event_queue.put(("release", now * 1000, frame_index, key), block=False)
+        frame_index, frame_pts, _ = self._get_current_frame_timing()
+        x, y = self._get_cursor_position()
+        self.event_queue.put(("release", now * 1000, frame_index, frame_pts, x, y, key), block=False)
 
     def run(self):
         self._set_high_priority()
@@ -353,7 +486,7 @@ class Recorder(QThread):
                 if first_frame_ms is not None:
                     self.metadata_manager.set_first_frame_time(first_frame_ms)
                     break
-                time.sleep(0.05)
+                time.sleep(0.001)  # Short sleep for responsive first-frame detection
             
             self.mouse_listener = mouse.Listener(
                 on_move=self.on_move,
@@ -384,11 +517,11 @@ class Recorder(QThread):
                     filtered_event_count += 1
                     continue
                 
-                processed_event = self._process_event(raw_event)
+                processed_event = self._process_event(raw_event, video_start_ms)
                 if not processed_event:
                     continue
                 
-                processed_event["second_in_video"] = (processed_event["time_stamp_ms"] - video_start_ms) / 1000.0
+                # second_in_video is already set in _process_event using PTS when available
                 self.events_file.write(json.dumps(processed_event) + "\n")
                 event_count += 1
             
@@ -411,7 +544,8 @@ class Recorder(QThread):
                 for line in f:
                     if line.startswith('#'):
                         continue
-                    native_match = re.match(r'n:\s*(\d+)\s+pts_time:([\d.]+)\s+perf_counter_ms:([\d.]+)', line)
+                    # Support both n: and frame_index: prefixes for video.log format compatibility
+                    native_match = re.match(r'(?:n|frame_index):\s*(\d+)\s+pts_time:([\d.]+)\s+perf_counter_ms:([\d.]+)', line)
                     if native_match:
                         frames.append({
                             'n': int(native_match.group(1)),
diff --git a/taggr/screen_recorder.py b/taggr/screen_recorder.py
index 7aac7d4..696098c 100644
--- a/taggr/screen_recorder.py
+++ b/taggr/screen_recorder.py
@@ -309,6 +309,8 @@ class ScreenRecorder:
         self._stderr_buffer = []  # Store stderr output for monitoring
         self._frame_index_lock = threading.Lock()
         self._current_frame_index = -1
+        self._current_frame_pts_seconds = -1.0
+        self._current_frame_perf_counter_ms = -1.0
         
         # First frame detection and video.log writing
         self._first_frame_detected = False
@@ -898,7 +900,8 @@ class ScreenRecorder:
                     output_path=self.output_path,
                     resolution=self.resolution,
                     fps=self.fps,
-                    frame_index_callback=self.update_current_frame_index
+                    frame_index_callback=self.update_current_frame_index,
+                    frame_timing_callback=self.update_current_frame_timing
                 )
                 result = self._native_windows_recorder.start_recording()
                 if result:
@@ -1606,12 +1609,50 @@ class ScreenRecorder:
         """Update the shared frame index from the active capture backend."""
         with self._frame_index_lock:
             self._current_frame_index = frame_index
+    
+    def update_current_frame_timing(self, frame_index: int, frame_pts_seconds: float, perf_counter_ms: float):
+        """
+        Update the current frame timing information from the capture backend.
+        
+        This method is thread-safe and provides PTS-based synchronization data
+        that can be used for precise event-to-frame mapping.
+        
+        Args:
+            frame_index: Frame number (0-based)
+            frame_pts_seconds: Presentation timestamp in seconds since recording start
+            perf_counter_ms: time.perf_counter() * 1000 at the moment of frame capture
+        """
+        with self._frame_index_lock:
+            self._current_frame_index = frame_index
+            self._current_frame_pts_seconds = frame_pts_seconds
+            self._current_frame_perf_counter_ms = perf_counter_ms
 
     def get_current_frame_index(self) -> int:
         """Return the most recent frame index reported by the capture backend."""
         with self._frame_index_lock:
             return self._current_frame_index
     
+    def get_current_frame_pts_seconds(self) -> float:
+        """
+        Return the most recent frame PTS in seconds.
+        
+        Returns:
+            Frame PTS in seconds, or -1.0 if not yet available
+        """
+        with self._frame_index_lock:
+            return self._current_frame_pts_seconds
+    
+    def get_current_frame_timing(self) -> Tuple[int, float, float]:
+        """
+        Return the current frame timing information.
+        
+        Returns:
+            Tuple of (frame_index, pts_seconds, perf_counter_ms)
+            All values are -1.0 if not yet available
+        """
+        with self._frame_index_lock:
+            return (self._current_frame_index, self._current_frame_pts_seconds, self._current_frame_perf_counter_ms)
+    
     def is_using_native_macos(self) -> bool:
         """
         Check if using native macOS ScreenCaptureKit for recording.
diff --git a/taggr/startup/__init__.py b/taggr/startup/__init__.py
index 06e77f1..57d5c2e 100644
--- a/taggr/startup/__init__.py
+++ b/taggr/startup/__init__.py
@@ -10,15 +10,30 @@ from .ubuntu_setup import (
     check_setup_completed,
     export_setup_script
 )
+from .system_requirements import (
+    check_system_requirements,
+    is_system_requirement_check_enabled,
+    evaluate_system_requirements,
+    RequirementStatus,
+    RequirementResult
+)
 
 __all__ = [
+    # Monitor checks
     'check_monitor_requirement',
     'get_monitor_count',
     'is_monitor_check_enabled',
+    # Windows elevation
     'check_windows_elevation',
+    # Ubuntu setup
     'check_and_prompt_setup',
     'is_ubuntu_24_04',
     'check_setup_completed',
     'export_setup_script',
+    # System requirements
+    'check_system_requirements',
+    'is_system_requirement_check_enabled',
+    'evaluate_system_requirements',
+    'RequirementStatus',
+    'RequirementResult',
 ]
-
diff --git a/taggr/startup/system_requirements.py b/taggr/startup/system_requirements.py
new file mode 100644
index 0000000..16a0433
--- /dev/null
+++ b/taggr/startup/system_requirements.py
@@ -0,0 +1,779 @@
+"""
+System requirements validation for Taggr application.
+
+Taggr requires minimum hardware specifications to ensure smooth recording:
+- CPU: Intel i5-equivalent or better (Ryzen 5+, Xeon, Atom, Ultra accepted)
+- RAM: ~7.5 GB or more
+- Disk I/O: Writable temp directory with reasonable speed
+- Power: Plugged in (not on battery/low power mode)
+
+The system requirements check can be disabled by:
+    - Setting TAGGR_SKIP_SYSTEM_REQUIREMENTS=1 environment variable
+    - Running in development mode (TAGGR_DEV_MODE=1, set by build.py --dev)
+"""
+
+import os
+import platform
+import re
+import subprocess
+import tempfile
+import time
+from dataclasses import dataclass
+from enum import Enum
+from typing import List, Optional, Tuple
+
+from PyQt6.QtCore import Qt
+from PyQt6.QtWidgets import QMessageBox, QVBoxLayout, QLabel, QWidget, QDialog, QPushButton, QHBoxLayout
+
+from ..constants import ui
+from ..logger import get_logger
+
+
+class RequirementStatus(Enum):
+    """Status of a system requirement check."""
+    PASS = "pass"
+    WARN = "warn"
+    FAIL = "fail"
+    SKIP = "skip"
+
+
+@dataclass
+class RequirementResult:
+    """Result of a single requirement check."""
+    name: str
+    status: RequirementStatus
+    detected_value: str
+    required_value: str
+    reason: str
+    suggestion: str
+
+
+# ============================================================================
+# Configuration Constants
+# ============================================================================
+
+# Minimum RAM in GB (configurable via environment variable)
+MIN_RAM_GB = float(os.environ.get('TAGGR_MIN_RAM_GB', '7.5'))
+
+# Intel CPU order for tier comparison
+INTEL_ORDER = ["i3", "i5", "i7", "i9"]
+
+# CPU tier extraction regex
+INTEL_TIER_REGEX = re.compile(r'\bi([3579])', re.IGNORECASE)
+
+
+# ============================================================================
+# CPU Detection and Validation
+# ============================================================================
+
+def _get_cpu_brand_string() -> str:
+    """
+    Get the CPU brand string using multiple fallback methods.
+    
+    Priority:
+    1. py-cpuinfo library (brand_raw or brand)
+    2. Platform-specific methods:
+       - macOS: sysctl -n machdep.cpu.brand_string
+       - Linux: /proc/cpuinfo "model name" or lscpu
+       - Windows: PROCESSOR_IDENTIFIER env var or WMI
+    3. Generic fallback: platform.processor() or uname().processor
+    
+    Returns:
+        CPU brand string or "Unknown" if detection fails
+    """
+    logger = get_logger('taggr.startup.system_requirements')
+    
+    # Try py-cpuinfo first
+    try:
+        import cpuinfo
+        info = cpuinfo.get_cpu_info()
+        brand = info.get('brand_raw') or info.get('brand')
+        if brand:
+            logger.debug(f"CPU detected via cpuinfo: {brand}")
+            return brand
+    except ImportError:
+        logger.debug("py-cpuinfo not available, using fallback methods")
+    except Exception as e:
+        logger.debug(f"cpuinfo failed: {e}")
+    
+    system = platform.system()
+    
+    # macOS fallback
+    if system == "Darwin":
+        try:
+            result = subprocess.run(
+                ['sysctl', '-n', 'machdep.cpu.brand_string'],
+                capture_output=True, text=True, timeout=5
+            )
+            if result.returncode == 0 and result.stdout.strip():
+                brand = result.stdout.strip()
+                logger.debug(f"CPU detected via sysctl: {brand}")
+                return brand
+        except Exception as e:
+            logger.debug(f"macOS sysctl failed: {e}")
+    
+    # Linux fallback
+    elif system == "Linux":
+        # Try /proc/cpuinfo
+        try:
+            with open('/proc/cpuinfo', 'r') as f:
+                for line in f:
+                    if 'model name' in line.lower():
+                        brand = line.split(':')[1].strip()
+                        logger.debug(f"CPU detected via /proc/cpuinfo: {brand}")
+                        return brand
+        except Exception as e:
+            logger.debug(f"Linux /proc/cpuinfo failed: {e}")
+        
+        # Try lscpu
+        try:
+            result = subprocess.run(
+                ['lscpu'],
+                capture_output=True, text=True, timeout=5
+            )
+            if result.returncode == 0:
+                for line in result.stdout.split('\n'):
+                    if 'model name' in line.lower():
+                        brand = line.split(':')[1].strip()
+                        logger.debug(f"CPU detected via lscpu: {brand}")
+                        return brand
+        except Exception as e:
+            logger.debug(f"Linux lscpu failed: {e}")
+    
+    # Windows fallback
+    elif system == "Windows":
+        # Try environment variable
+        processor_id = os.environ.get('PROCESSOR_IDENTIFIER')
+        if processor_id:
+            logger.debug(f"CPU detected via PROCESSOR_IDENTIFIER: {processor_id}")
+            return processor_id
+        
+        # Try WMI
+        try:
+            import wmi
+            w = wmi.WMI()
+            for proc in w.Win32_Processor():
+                brand = proc.Name
+                if brand:
+                    logger.debug(f"CPU detected via WMI: {brand}")
+                    return brand
+        except Exception as e:
+            logger.debug(f"Windows WMI failed: {e}")
+    
+    # Generic fallback
+    try:
+        processor = platform.processor()
+        if processor:
+            logger.debug(f"CPU detected via platform.processor(): {processor}")
+            return processor
+    except Exception:
+        pass
+    
+    try:
+        processor = platform.uname().processor
+        if processor:
+            logger.debug(f"CPU detected via uname().processor: {processor}")
+            return processor
+    except Exception:
+        pass
+    
+    logger.warning("Could not detect CPU brand string")
+    return "Unknown"
+
+
+def _check_intel_cpu(brand: str) -> Tuple[bool, str]:
+    """
+    Check if Intel CPU meets minimum tier requirements.
+    
+    Accepts:
+    - Core i5, i7, i9 (or higher)
+    - Xeon (server-class)
+    - Atom (embedded/low-power but capable)
+    - Ultra (newer mobile CPUs)
+    
+    Args:
+        brand: CPU brand string
+        
+    Returns:
+        Tuple of (passes, reason)
+    """
+    brand_upper = brand.upper()
+    
+    # Accept special Intel variants
+    if 'XEON' in brand_upper:
+        return True, "Intel Xeon (server-class) accepted"
+    if 'ATOM' in brand_upper:
+        return True, "Intel Atom accepted"
+    if 'ULTRA' in brand_upper:
+        return True, "Intel Ultra accepted"
+    
+    # Check Core series tier
+    match = INTEL_TIER_REGEX.search(brand)
+    if match:
+        tier = match.group(1).lower()
+        tier_with_i = f"i{tier}"
+        
+        if tier_with_i in INTEL_ORDER:
+            tier_index = INTEL_ORDER.index(tier_with_i)
+            min_tier_index = INTEL_ORDER.index("i5")
+            
+            if tier_index >= min_tier_index:
+                return True, f"Intel Core {tier_with_i} meets minimum requirement (i5+)"
+            else:
+                return False, f"Intel Core {tier_with_i} is below minimum tier (requires i5 or better)"
+    
+    # Intel CPU but couldn't determine tier - accept with warning
+    return True, "Intel CPU detected (tier unknown, accepting)"
+
+
+def _check_amd_cpu(brand: str) -> Tuple[bool, str]:
+    """
+    Check if AMD CPU meets minimum tier requirements.
+    
+    Accepts:
+    - Ryzen 5 or higher (5, 7, 9)
+    - Any Ryzen if series number unknown
+    - EPYC (server-class)
+    - Threadripper (workstation-class)
+    
+    Args:
+        brand: CPU brand string
+        
+    Returns:
+        Tuple of (passes, reason)
+    """
+    brand_upper = brand.upper()
+    
+    # Accept special AMD variants
+    if 'EPYC' in brand_upper:
+        return True, "AMD EPYC (server-class) accepted"
+    if 'THREADRIPPER' in brand_upper:
+        return True, "AMD Threadripper (workstation-class) accepted"
+    
+    # Check Ryzen series
+    if 'RYZEN' in brand_upper:
+        # Try to extract series number (Ryzen 3, 5, 7, 9)
+        ryzen_match = re.search(r'RYZEN\s*(\d)', brand_upper)
+        if ryzen_match:
+            series = int(ryzen_match.group(1))
+            if series >= 5:
+                return True, f"AMD Ryzen {series} meets minimum requirement (Ryzen 5+)"
+            else:
+                return False, f"AMD Ryzen {series} is below minimum tier (requires Ryzen 5 or better)"
+        else:
+            # Ryzen but couldn't determine series - accept
+            return True, "AMD Ryzen detected (series unknown, accepting)"
+    
+    # AMD CPU but not Ryzen/EPYC/Threadripper - likely older
+    return False, "AMD CPU detected but not in accepted categories (Ryzen 5+, EPYC, Threadripper)"
+
+
+def _check_cpu() -> RequirementResult:
+    """
+    Check if CPU meets minimum requirements.
+    
+    Returns:
+        RequirementResult with check status
+    """
+    brand = _get_cpu_brand_string()
+    brand_upper = brand.upper()
+    
+    # Intel CPU check
+    if 'INTEL' in brand_upper:
+        passes, reason = _check_intel_cpu(brand)
+        return RequirementResult(
+            name="CPU",
+            status=RequirementStatus.PASS if passes else RequirementStatus.FAIL,
+            detected_value=brand,
+            required_value="Intel i5+ / Xeon / Atom / Ultra",
+            reason=reason,
+            suggestion="Upgrade to Intel Core i5 or better for optimal recording performance" if not passes else ""
+        )
+    
+    # AMD CPU check
+    if 'AMD' in brand_upper:
+        passes, reason = _check_amd_cpu(brand)
+        return RequirementResult(
+            name="CPU",
+            status=RequirementStatus.PASS if passes else RequirementStatus.FAIL,
+            detected_value=brand,
+            required_value="AMD Ryzen 5+ / EPYC / Threadripper",
+            reason=reason,
+            suggestion="Upgrade to AMD Ryzen 5 or better for optimal recording performance" if not passes else ""
+        )
+    
+    # Apple Silicon (always accepted)
+    if 'APPLE' in brand_upper or 'M1' in brand_upper or 'M2' in brand_upper or 'M3' in brand_upper or 'M4' in brand_upper:
+        return RequirementResult(
+            name="CPU",
+            status=RequirementStatus.PASS,
+            detected_value=brand,
+            required_value="Apple Silicon",
+            reason="Apple Silicon detected and accepted",
+            suggestion=""
+        )
+    
+    # Unknown vendor - fail with detailed reason
+    return RequirementResult(
+        name="CPU",
+        status=RequirementStatus.FAIL,
+        detected_value=brand,
+        required_value="Intel i5+ / AMD Ryzen 5+ / Apple Silicon",
+        reason=f"Unknown CPU vendor: {brand}. Cannot verify compatibility.",
+        suggestion="Ensure your CPU is Intel Core i5+, AMD Ryzen 5+, or Apple Silicon"
+    )
+
+
+# ============================================================================
+# RAM Detection and Validation
+# ============================================================================
+
+def _check_ram() -> RequirementResult:
+    """
+    Check if system has sufficient RAM.
+    
+    Returns:
+        RequirementResult with check status
+    """
+    try:
+        import psutil
+        total_bytes = psutil.virtual_memory().total
+        total_gb = total_bytes / (1024 ** 3)
+        
+        passes = total_gb >= MIN_RAM_GB
+        
+        return RequirementResult(
+            name="RAM",
+            status=RequirementStatus.PASS if passes else RequirementStatus.FAIL,
+            detected_value=f"{total_gb:.1f} GB",
+            required_value=f"{MIN_RAM_GB:.1f} GB",
+            reason=f"System has {total_gb:.1f} GB RAM" + (" (sufficient)" if passes else f" (minimum {MIN_RAM_GB:.1f} GB required)"),
+            suggestion="" if passes else f"Add more RAM to reach at least {MIN_RAM_GB:.1f} GB for smooth recording"
+        )
+    except Exception as e:
+        return RequirementResult(
+            name="RAM",
+            status=RequirementStatus.WARN,
+            detected_value="Unknown",
+            required_value=f"{MIN_RAM_GB:.1f} GB",
+            reason=f"Could not detect RAM: {e}",
+            suggestion="Ensure system has at least 8 GB RAM"
+        )
+
+
+# ============================================================================
+# Disk I/O Validation
+# ============================================================================
+
+def _check_disk_io() -> RequirementResult:
+    """
+    Check if disk I/O is working by performing a test write/read.
+    
+    Returns:
+        RequirementResult with check status
+    """
+    logger = get_logger('taggr.startup.system_requirements')
+    
+    try:
+        # Get temp directory
+        temp_dir = tempfile.gettempdir()
+        test_file = os.path.join(temp_dir, f'taggr_io_test_{os.getpid()}.tmp')
+        
+        # Test write
+        test_data = b'Taggr disk I/O test ' * 1000  # ~20KB
+        start_time = time.perf_counter()
+        
+        with open(test_file, 'wb') as f:
+            f.write(test_data)
+            f.flush()
+            os.fsync(f.fileno())
+        
+        write_time = time.perf_counter() - start_time
+        
+        # Test read
+        start_time = time.perf_counter()
+        with open(test_file, 'rb') as f:
+            read_data = f.read()
+        read_time = time.perf_counter() - start_time
+        
+        # Cleanup
+        try:
+            os.remove(test_file)
+        except Exception:
+            pass
+        
+        # Verify data integrity
+        if read_data != test_data:
+            return RequirementResult(
+                name="Disk I/O",
+                status=RequirementStatus.FAIL,
+                detected_value="Data integrity error",
+                required_value="Writable temp directory",
+                reason="Disk I/O test failed: read data doesn't match written data",
+                suggestion="Check disk health and available space"
+            )
+        
+        total_time_ms = (write_time + read_time) * 1000
+        logger.debug(f"Disk I/O test: write={write_time*1000:.1f}ms, read={read_time*1000:.1f}ms")
+        
+        # Warn if very slow (>500ms for 20KB)
+        if total_time_ms > 500:
+            return RequirementResult(
+                name="Disk I/O",
+                status=RequirementStatus.WARN,
+                detected_value=f"{total_time_ms:.0f}ms for 20KB",
+                required_value="Fast temp directory access",
+                reason=f"Disk I/O is slow ({total_time_ms:.0f}ms for test)",
+                suggestion="Recording may be affected. Consider using an SSD or faster storage"
+            )
+        
+        return RequirementResult(
+            name="Disk I/O",
+            status=RequirementStatus.PASS,
+            detected_value=f"{total_time_ms:.0f}ms for 20KB",
+            required_value="Writable temp directory",
+            reason="Disk I/O test passed",
+            suggestion=""
+        )
+        
+    except PermissionError:
+        return RequirementResult(
+            name="Disk I/O",
+            status=RequirementStatus.FAIL,
+            detected_value="Permission denied",
+            required_value="Writable temp directory",
+            reason="Cannot write to temp directory (permission denied)",
+            suggestion="Check temp directory permissions or run as administrator"
+        )
+    except Exception as e:
+        return RequirementResult(
+            name="Disk I/O",
+            status=RequirementStatus.FAIL,
+            detected_value="Error",
+            required_value="Writable temp directory",
+            reason=f"Disk I/O test failed: {e}",
+            suggestion="Check disk health and available space"
+        )
+
+
+# ============================================================================
+# Power State Validation
+# ============================================================================
+
+def _check_power_state() -> RequirementResult:
+    """
+    Check if system is plugged in and not in low-power/energy saver mode.
+    
+    Returns:
+        RequirementResult with check status
+    """
+    logger = get_logger('taggr.startup.system_requirements')
+    system = platform.system()
+    
+    try:
+        import psutil
+        battery = psutil.sensors_battery()
+        
+        if battery is None:
+            # No battery (desktop) - always pass
+            return RequirementResult(
+                name="Power",
+                status=RequirementStatus.PASS,
+                detected_value="AC Power (no battery)",
+                required_value="Plugged in",
+                reason="Desktop system detected (no battery)",
+                suggestion=""
+            )
+        
+        # Check if plugged in
+        if battery.power_plugged:
+            # Check for energy saver mode
+            energy_saver_active = False
+            energy_saver_reason = ""
+            
+            if system == "Darwin":
+                # macOS: Check Low Power Mode
+                try:
+                    result = subprocess.run(
+                        ['pmset', '-g'],
+                        capture_output=True, text=True, timeout=5
+                    )
+                    if 'lowpowermode' in result.stdout.lower() and '1' in result.stdout:
+                        energy_saver_active = True
+                        energy_saver_reason = "Low Power Mode is enabled"
+                except Exception as e:
+                    logger.debug(f"Could not check macOS Low Power Mode: {e}")
+            
+            elif system == "Windows":
+                # Windows: Check power plan
+                try:
+                    result = subprocess.run(
+                        ['powercfg', '/getactivescheme'],
+                        capture_output=True, text=True, timeout=5
+                    )
+                    output = result.stdout.lower()
+                    if 'power saver' in output or 'energy saver' in output:
+                        energy_saver_active = True
+                        energy_saver_reason = "Power Saver mode is active"
+                except Exception as e:
+                    logger.debug(f"Could not check Windows power plan: {e}")
+            
+            if energy_saver_active:
+                return RequirementResult(
+                    name="Power",
+                    status=RequirementStatus.WARN,
+                    detected_value=f"Plugged in ({energy_saver_reason})",
+                    required_value="Plugged in, performance mode",
+                    reason=energy_saver_reason,
+                    suggestion="Disable energy saver mode for optimal recording performance"
+                )
+            
+            return RequirementResult(
+                name="Power",
+                status=RequirementStatus.PASS,
+                detected_value=f"Plugged in ({battery.percent:.0f}%)",
+                required_value="Plugged in",
+                reason="System is plugged in",
+                suggestion=""
+            )
+        else:
+            # On battery
+            return RequirementResult(
+                name="Power",
+                status=RequirementStatus.FAIL,
+                detected_value=f"On battery ({battery.percent:.0f}%)",
+                required_value="Plugged in",
+                reason="System is running on battery power",
+                suggestion="Plug in your device for reliable recording performance"
+            )
+            
+    except Exception as e:
+        logger.debug(f"Could not check power state: {e}")
+        return RequirementResult(
+            name="Power",
+            status=RequirementStatus.WARN,
+            detected_value="Unknown",
+            required_value="Plugged in",
+            reason=f"Could not detect power state: {e}",
+            suggestion="Ensure system is plugged in for optimal performance"
+        )
+
+
+# ============================================================================
+# Main Check Functions
+# ============================================================================
+
+def is_system_requirement_check_enabled() -> bool:
+    """
+    Check if the system requirements check is enabled.
+    
+    The check can be disabled by setting the environment variable:
+        TAGGR_SKIP_SYSTEM_REQUIREMENTS=1
+    
+    The check is also automatically disabled in development mode when:
+        TAGGR_DEV_MODE=1 (set by build.py --dev)
+    
+    Returns:
+        True if check should be performed, False if it should be skipped
+    """
+    # Skip if dev mode is enabled (set by build.py --dev)
+    dev_mode = os.environ.get('TAGGR_DEV_MODE', '').strip()
+    if dev_mode in ('1', 'true', 'True', 'TRUE', 'yes', 'Yes', 'YES'):
+        return False
+    
+    # Skip if explicitly disabled
+    skip_check = os.environ.get('TAGGR_SKIP_SYSTEM_REQUIREMENTS', 'false').strip()
+    return skip_check not in ('1', 'true', 'True', 'TRUE', 'yes', 'Yes', 'YES')
+
+
+def evaluate_system_requirements() -> List[RequirementResult]:
+    """
+    Evaluate all system requirements.
+    
+    Returns:
+        List of RequirementResult for each check
+    """
+    results = []
+    
+    # CPU check
+    results.append(_check_cpu())
+    
+    # RAM check
+    results.append(_check_ram())
+    
+    # Disk I/O check
+    results.append(_check_disk_io())
+    
+    # Power state check
+    results.append(_check_power_state())
+    
+    return results
+
+
+def _format_requirements_message(results: List[RequirementResult]) -> str:
+    """
+    Format requirements results into a user-friendly message.
+    
+    Args:
+        results: List of RequirementResult
+        
+    Returns:
+        Formatted message string
+    """
+    lines = []
+    
+    # Summary of detected hardware
+    cpu_result = next((r for r in results if r.name == "CPU"), None)
+    ram_result = next((r for r in results if r.name == "RAM"), None)
+    
+    lines.append("Detected Hardware:")
+    if cpu_result:
+        lines.append(f"  • CPU: {cpu_result.detected_value}")
+    if ram_result:
+        lines.append(f"  • RAM: {ram_result.detected_value}")
+    lines.append("")
+    
+    lines.append("Requirements:")
+    if cpu_result:
+        lines.append(f"  • CPU: {cpu_result.required_value}")
+    if ram_result:
+        lines.append(f"  • RAM: {ram_result.required_value}")
+    lines.append("")
+    
+    # Status of each check
+    lines.append("Check Results:")
+    for result in results:
+        status_icon = {
+            RequirementStatus.PASS: "✓",
+            RequirementStatus.WARN: "⚠",
+            RequirementStatus.FAIL: "✗",
+            RequirementStatus.SKIP: "○"
+        }.get(result.status, "?")
+        
+        lines.append(f"  {status_icon} {result.name}: {result.reason}")
+        if result.suggestion:
+            lines.append(f"      → {result.suggestion}")
+    
+    return "\n".join(lines)
+
+
+def check_system_requirements(app, parent=None) -> bool:
+    """
+    Check if the system meets minimum hardware requirements.
+    
+    Shows a blocking modal dialog if requirements are not met.
+    
+    Args:
+        app: QApplication instance
+        parent: Optional parent widget for the dialog
+        
+    Returns:
+        True if requirements are met or check is disabled, False if user exits
+    """
+    logger = get_logger('taggr.startup.system_requirements')
+    
+    # Check if system requirements check is disabled
+    if not is_system_requirement_check_enabled():
+        dev_mode = os.environ.get('TAGGR_DEV_MODE', '').strip()
+        skip_check = os.environ.get('TAGGR_SKIP_SYSTEM_REQUIREMENTS', '').strip()
+        
+        if dev_mode in ('1', 'true', 'True', 'TRUE', 'yes', 'Yes', 'YES'):
+            logger.warning("System requirements check DISABLED - running in development mode (TAGGR_DEV_MODE=1)")
+        elif skip_check in ('1', 'true', 'True', 'TRUE', 'yes', 'Yes', 'YES'):
+            logger.warning("System requirements check DISABLED via TAGGR_SKIP_SYSTEM_REQUIREMENTS environment variable")
+        
+        return True
+    
+    # Evaluate requirements
+    logger.info("Evaluating system requirements...")
+    results = evaluate_system_requirements()
+    
+    # Log results
+    for result in results:
+        log_method = {
+            RequirementStatus.PASS: logger.info,
+            RequirementStatus.WARN: logger.warning,
+            RequirementStatus.FAIL: logger.error,
+            RequirementStatus.SKIP: logger.info
+        }.get(result.status, logger.info)
+        log_method(f"  {result.name}: {result.status.value} - {result.reason}")
+    
+    # Check for failures
+    failures = [r for r in results if r.status == RequirementStatus.FAIL]
+    warnings = [r for r in results if r.status == RequirementStatus.WARN]
+    
+    if not failures:
+        if warnings:
+            logger.warning(f"System requirements check passed with {len(warnings)} warning(s)")
+        else:
+            logger.info("System requirements check passed")
+        return True
+    
+    # Requirements not met - show blocking dialog
+    logger.error(f"System requirements check FAILED: {len(failures)} requirement(s) not met")
+    
+    message = _format_requirements_message(results)
+    
+    msg_box = QMessageBox(parent)
+    msg_box.setIcon(QMessageBox.Icon.Critical)
+    msg_box.setWindowTitle("Scaler Taggr - System Requirements")
+    msg_box.setText("⚠️ System Requirements Not Met")
+    msg_box.setInformativeText(
+        "Your system does not meet the minimum hardware requirements for Taggr.\n\n"
+        f"{message}\n\n"
+        "Recording performance may be severely impacted.\n\n"
+        "Actions:\n"
+        "• Exit: Close the application"
+    )
+    
+    # Only exit button - requirements are blocking
+    exit_button = msg_box.addButton("Exit", QMessageBox.ButtonRole.RejectRole)
+    msg_box.setDefaultButton(exit_button)
+    
+    # Style the message box
+    msg_box.setStyleSheet(f"""
+        QMessageBox {{
+            background-color: {ui.COLOR_SURFACE_ELEVATED};
+            min-width: 550px;
+        }}
+        QLabel {{
+            color: {ui.COLOR_TEXT_PRIMARY};
+            font-size: {ui.FONT_SIZE_BODY}px;
+            font-family: monospace;
+        }}
+        QPushButton {{
+            background-color: {ui.COLOR_DANGER};
+            color: white;
+            border: none;
+            padding: 10px 20px;
+            font-size: {ui.FONT_SIZE_BODY}px;
+            font-weight: bold;
+            border-radius: {ui.BUTTON_BORDER_RADIUS}px;
+            min-width: 100px;
+            min-height: {ui.BUTTON_HEIGHT_SMALL}px;
+        }}
+        QPushButton:hover {{
+            background-color: {ui.COLOR_DANGER_HOVER};
+        }}
+        QPushButton:pressed {{
+            background-color: {ui.COLOR_DANGER_PRESSED};
+        }}
+    """)
+    
+    # Ensure dialog appears on top and is modal
+    msg_box.setWindowFlags(
+        msg_box.windowFlags() | Qt.WindowType.WindowStaysOnTopHint
+    )
+    msg_box.setModal(True)
+    msg_box.raise_()
+    msg_box.activateWindow()
+    
+    # Show dialog
+    msg_box.exec()
+    
+    # Log exit reason
+    logger.error("Application startup cancelled - system requirements not met")
+    for result in failures:
+        logger.error(f"  - {result.name}: {result.reason}")
+    
+    return False
diff --git a/taggr/windows_screen_recorder.py b/taggr/windows_screen_recorder.py
index da4e1f8..38eabe8 100644
--- a/taggr/windows_screen_recorder.py
+++ b/taggr/windows_screen_recorder.py
@@ -157,13 +157,16 @@ class CursorCapture:
         
         return sprite
     
-    def draw_cursor_on_frame(self, frame, sprite: Optional["np.ndarray"] = None):
+    def draw_cursor_on_frame(self, frame, sprite: Optional["np.ndarray"] = None, 
+                               cursor_pos: Optional[Tuple[int, int]] = None):
         """
         Draw a simple cursor indicator on the frame.
         
         Args:
             frame: BGR or BGRA numpy array
             sprite: pre-rendered cursor sprite
+            cursor_pos: Optional (x, y) cursor position override. If not provided,
+                       queries current cursor position (may not match frame capture time).
             
         Returns:
             Frame with cursor drawn
@@ -172,7 +175,11 @@ class CursorCapture:
             return frame
         
         try:
-            x, y = self.get_cursor_pos()
+            # Use provided cursor_pos if available, else query live position
+            if cursor_pos is not None:
+                x, y = cursor_pos
+            else:
+                x, y = self.get_cursor_pos()
             
             if sprite is None:
                 sprite = self.create_sprite()
@@ -259,6 +266,7 @@ class FramePayload(NamedTuple):
     pts_seconds: float
     capture_time_ms: float
     frame_number: int
+    cursor_pos: Optional[Tuple[int, int]] = None  # Cursor position at frame capture time
 
 
 # ============================================================================
@@ -786,7 +794,8 @@ class NativeWindowsScreenRecorder:
     """Native Windows screen recorder using Desktop Duplication API + Media Foundation."""
     
     def __init__(self, output_path: str, resolution: str = "1920x1080", fps: int = 30,
-                 frame_index_callback: Optional[Callable[[int], None]] = None):
+                 frame_index_callback: Optional[Callable[[int], None]] = None,
+                 frame_timing_callback: Optional[Callable[[int, float, float], None]] = None):
         self.logger = get_logger('taggr.windows_screen_recorder')
         self.output_path = output_path
         self.output_file = os.path.join(output_path, "video.mp4")
@@ -794,6 +803,7 @@ class NativeWindowsScreenRecorder:
         self.resolution = resolution
         self.fps = fps
         self._frame_index_callback = frame_index_callback
+        self._frame_timing_callback = frame_timing_callback  # Callback for (frame_index, pts_seconds, perf_counter_ms)
         
         self.width, self.height = self._parse_resolution(resolution)
         
@@ -808,6 +818,7 @@ class NativeWindowsScreenRecorder:
         self._writer_thread: Optional[threading.Thread] = None
         self._stop_capture = threading.Event()
         self._queue_block_events = 0
+        self._none_frame_count = 0  # Track None frames returned by dxcam
         self._capture_last_pts_seconds = 0.0
         
         self._video_log_file = os.path.join(output_path, "video.log")
@@ -870,10 +881,18 @@ class NativeWindowsScreenRecorder:
         resized = self._resize_with_letterbox(bgra, target_height, target_width, out=self._resized_canvas)
         return resized
 
-    def _apply_cursor_if_enabled(self, frame: "np.ndarray") -> "np.ndarray":
-        """Draw cursor overlay outside of capture loop."""
+    def _apply_cursor_if_enabled(self, frame: "np.ndarray", 
+                                   cursor_pos: Optional[Tuple[int, int]] = None) -> "np.ndarray":
+        """
+        Draw cursor overlay on frame.
+        
+        Args:
+            frame: Frame to draw cursor on
+            cursor_pos: Optional cursor position captured at frame time.
+                       If not provided, falls back to live cursor query.
+        """
         if self._draw_cursor and self._cursor_capture and self._cursor_sprite is not None:
-            return self._cursor_capture.draw_cursor_on_frame(frame, self._cursor_sprite)
+            return self._cursor_capture.draw_cursor_on_frame(frame, self._cursor_sprite, cursor_pos)
         return frame
 
     def _resize_with_letterbox(self, frame: "np.ndarray", target_height: int, target_width: int, out: Optional["np.ndarray"] = None) -> "np.ndarray":
@@ -948,6 +967,7 @@ class NativeWindowsScreenRecorder:
                 try:
                     frame = self._camera.get_latest_frame()
                     if frame is None:
+                        self._none_frame_count += 1
                         continue
                     
                     if not self._first_frame_detected:
@@ -964,12 +984,25 @@ class NativeWindowsScreenRecorder:
                     
                     frame_num = self._frame_count
                     self._frame_count += 1
+                    
+                    # Calculate PTS using true VFR: now - anchor_time
+                    now = time.perf_counter()
+                    pts_seconds = now - anchor_time
+                    calculated_time_ms = now * 1000.0
+                    self._capture_last_pts_seconds = pts_seconds
+                    
+                    # Capture cursor position at this exact moment
+                    cursor_pos = None
+                    if self._cursor_capture:
+                        cursor_pos = self._cursor_capture.get_cursor_pos()
+                    
+                    # Call frame index callback
                     if self._frame_index_callback:
                         self._frame_index_callback(frame_num)
                     
-                    pts_seconds = frame_num * frame_interval
-                    calculated_time_ms = (anchor_time + pts_seconds) * 1000.0
-                    self._capture_last_pts_seconds = pts_seconds
+                    # Call frame timing callback with full timing info
+                    if self._frame_timing_callback:
+                        self._frame_timing_callback(frame_num, pts_seconds, calculated_time_ms)
                     
                     if self._frame_queue:
                         payload = FramePayload(
@@ -977,6 +1010,7 @@ class NativeWindowsScreenRecorder:
                             pts_seconds=pts_seconds,
                             capture_time_ms=calculated_time_ms,
                             frame_number=frame_num,
+                            cursor_pos=cursor_pos,
                         )
                         try:
                             self._frame_queue.put(payload, timeout=0.5)
@@ -1049,7 +1083,7 @@ class NativeWindowsScreenRecorder:
                 return
             
             first_pts = first_payload.pts_seconds
-            first_frame = self._apply_cursor_if_enabled(first_payload.frame)
+            first_frame = self._apply_cursor_if_enabled(first_payload.frame, first_payload.cursor_pos)
             
             input_height, input_width = first_frame.shape[:2]
             
@@ -1147,7 +1181,7 @@ class NativeWindowsScreenRecorder:
                 try:
                     payload = self._frame_queue.get(timeout=0.1)
                     if payload:
-                        frame = self._apply_cursor_if_enabled(payload.frame)
+                        frame = self._apply_cursor_if_enabled(payload.frame, payload.cursor_pos)
                         pts_seconds = payload.pts_seconds
                         
                         if pts_seconds is None:
@@ -1230,7 +1264,7 @@ class NativeWindowsScreenRecorder:
                 return
             
             first_pts = first_payload.pts_seconds
-            first_frame = self._apply_cursor_if_enabled(first_payload.frame)
+            first_frame = self._apply_cursor_if_enabled(first_payload.frame, first_payload.cursor_pos)
             
             h, w = first_frame.shape[:2]
             self.logger.info(f"ffmpeg VFR fallback: {w}x{h} -> {self.width}x{self.height}")
@@ -1265,7 +1299,7 @@ class NativeWindowsScreenRecorder:
                 try:
                     payload = self._frame_queue.get(timeout=0.1)
                     if payload:
-                        frame = self._apply_cursor_if_enabled(payload.frame)
+                        frame = self._apply_cursor_if_enabled(payload.frame, payload.cursor_pos)
                         pts_seconds = payload.pts_seconds
                         
                         # Feed at real capture rate
@@ -1323,7 +1357,7 @@ class NativeWindowsScreenRecorder:
                 return
             
             first_pts = first_payload.pts_seconds
-            first_frame = self._apply_cursor_if_enabled(first_payload.frame)
+            first_frame = self._apply_cursor_if_enabled(first_payload.frame, first_payload.cursor_pos)
             
             h, w = first_frame.shape[:2]
             self.logger.info(f"ffmpeg VFR: {w}x{h} -> {self.width}x{self.height}")
@@ -1363,7 +1397,7 @@ class NativeWindowsScreenRecorder:
                 try:
                     payload = self._frame_queue.get(timeout=0.1)
                     if payload:
-                        frame = self._apply_cursor_if_enabled(payload.frame)
+                        frame = self._apply_cursor_if_enabled(payload.frame, payload.cursor_pos)
                         pts_seconds = payload.pts_seconds
                         
                         # Calculate when this frame should be written based on its PTS
@@ -1435,6 +1469,7 @@ class NativeWindowsScreenRecorder:
             self._use_ffmpeg_fallback = False
             self._last_pts_seconds = 0.0
             self._queue_block_events = 0
+            self._none_frame_count = 0
             self._capture_last_pts_seconds = 0.0
             
             self._video_log_writer_thread = threading.Thread(
@@ -1456,10 +1491,10 @@ class NativeWindowsScreenRecorder:
             )
             self._capture_thread.start()
             
-            # Wait for first frame
+            # Wait for first frame with short sleep for responsive detection
             wait_start = time.time()
             while not self._first_frame_detected and (time.time() - wait_start) < 5.0:
-                time.sleep(0.05)
+                time.sleep(0.001)  # Short sleep for responsive first-frame detection
             
             if self._first_frame_detected:
                 self._is_recording = True
@@ -1509,6 +1544,8 @@ class NativeWindowsScreenRecorder:
                     self.logger.info(f"  Video duration: {video_duration_s:.2f}s at {self.fps}fps")
             if self._queue_block_events > 0:
                 self.logger.warning(f"Frame queue stalled {self._queue_block_events} times waiting for encoder")
+            if self._none_frame_count > 0:
+                self.logger.info(f"None-frame count from dxcam: {self._none_frame_count}")
             
             # Handle output based on which encoder was used
             if self._use_ffmpeg_fallback:
@@ -1558,7 +1595,12 @@ class NativeWindowsScreenRecorder:
                 self.logger.warning(f"Error deleting partial video.mp4: {e}")
     
     def _remux_to_mp4(self) -> bool:
-        """Remux MKV to MP4."""
+        """
+        Remux MKV to MP4 using stream copy (no re-encode).
+        
+        Stream copy is fast - even large files complete quickly since we're
+        just repackaging the data, not decoding/encoding it.
+        """
         try:
             size = os.path.getsize(self.temp_output_file)
             self.logger.info(f"Remuxing MKV ({size / 1024 / 1024:.2f} MB) to MP4...")
@@ -1572,11 +1614,21 @@ class NativeWindowsScreenRecorder:
             startupinfo.wShowWindow = subprocess.SW_HIDE
             
             capture_duration = max(self._capture_last_pts_seconds, self._last_pts_seconds, 0.0)
-            encoded_duration = self._get_video_duration_seconds(self.temp_output_file) or 0.0
+            # Use longer timeout for duration probe since large files may take time
+            encoded_duration = self._get_video_duration_seconds(self.temp_output_file, timeout=60) or 0.0
             self.logger.info(
                 f"Capture duration: {capture_duration:.3f}s, encoded duration before scaling: {encoded_duration:.3f}s"
             )
             
+            # Warn if significant duration mismatch
+            if capture_duration > 0 and encoded_duration > 0:
+                duration_diff = abs(capture_duration - encoded_duration)
+                if duration_diff > 1.0:
+                    self.logger.warning(
+                        f"Duration mismatch detected: capture={capture_duration:.2f}s vs encoded={encoded_duration:.2f}s "
+                        f"(difference: {duration_diff:.2f}s)"
+                    )
+            
             ratio = 1.0
             needs_scaling = False
             if capture_duration > 0 and encoded_duration > 0:
@@ -1609,14 +1661,25 @@ class NativeWindowsScreenRecorder:
                     '-y', self.output_file
                 ]
             
+            # Extended timeout (1200s) for stream copy - stream copy is fast so this is generous
+            # but large files or slow disks may need extra time
             result = subprocess.run(
                 cmd,
-                capture_output=True, timeout=180, startupinfo=startupinfo, text=True
+                capture_output=True, timeout=1200, startupinfo=startupinfo, text=True
             )
             
             if result.returncode == 0 and os.path.exists(self.output_file):
                 mp4_size = os.path.getsize(self.output_file)
                 if mp4_size > 0:
+                    # Verify output duration matches expected
+                    output_duration = self._get_video_duration_seconds(self.output_file, timeout=60)
+                    if output_duration and capture_duration > 0:
+                        output_diff = abs(output_duration - capture_duration)
+                        if output_diff > 1.0:
+                            self.logger.warning(
+                                f"Output duration mismatch: expected ~{capture_duration:.2f}s, got {output_duration:.2f}s"
+                            )
+                    
                     self.logger.info(f"✓ Remux successful! MP4: {mp4_size / 1024 / 1024:.2f} MB")
                     try:
                         os.remove(self.temp_output_file)
@@ -1624,14 +1687,20 @@ class NativeWindowsScreenRecorder:
                         pass
                     return True
             
-            self.logger.error(f"Remux failed: {result.stderr.decode()[-500:]}")
+            self.logger.error(f"Remux failed: {result.stderr[-500:] if result.stderr else 'No error output'}")
             return False
         except Exception as e:
             self.logger.error(f"Remux error: {e}")
             return False
 
-    def _get_video_duration_seconds(self, path: str) -> Optional[float]:
-        """Use ffmpeg metadata output to estimate video duration."""
+    def _get_video_duration_seconds(self, path: str, timeout: int = 30) -> Optional[float]:
+        """
+        Use ffmpeg metadata output to estimate video duration.
+        
+        Args:
+            path: Path to video file
+            timeout: Timeout in seconds for ffmpeg probe (default: 30, use 60+ for large files)
+        """
         try:
             startupinfo = subprocess.STARTUPINFO()
             startupinfo.dwFlags |= subprocess.STARTF_USESHOWWINDOW
@@ -1639,7 +1708,7 @@ class NativeWindowsScreenRecorder:
             
             result = subprocess.run(
                 [self.ffmpeg_cmd, '-i', path],
-                capture_output=True, text=True, timeout=30, startupinfo=startupinfo
+                capture_output=True, text=True, timeout=timeout, startupinfo=startupinfo
             )
             output = (result.stdout or "") + (result.stderr or "")
             match = re.search(r'Duration:\s*(\d+):(\d+):(\d+(?:\.\d+)?)', output)
